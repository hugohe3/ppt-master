#!/usr/bin/env python3
"""
PDF è½¬ Markdown å·¥å…·
ä½¿ç”¨ PyMuPDF æå– PDF æ–‡æœ¬å†…å®¹å¹¶è½¬æ¢ä¸º Markdown æ ¼å¼
æ”¯æŒæ ‡é¢˜å±‚çº§ã€ç²—ä½“ã€æ–œä½“ã€åˆ—è¡¨è¯†åˆ«
"""

import fitz  # PyMuPDF
import argparse
import os
import re
from pathlib import Path
from collections import Counter


def analyze_font_sizes(doc) -> dict:
    """åˆ†ææ–‡æ¡£ä¸­çš„å­—ä½“å¤§å°åˆ†å¸ƒï¼Œç”¨äºæ¨æ–­æ ‡é¢˜å±‚çº§"""
    size_counter = Counter()
    
    for page in doc:
        blocks = page.get_text("dict")["blocks"]
        for block in blocks:
            if block["type"] == 0:
                for line in block["lines"]:
                    for span in line["spans"]:
                        size = round(span["size"], 1)
                        text = span["text"].strip()
                        if text:
                            size_counter[size] += len(text)
    
    if not size_counter:
        return {"body": 12, "h1": 24, "h2": 18, "h3": 14}
    
    sorted_sizes = sorted(size_counter.items(), key=lambda x: x[1], reverse=True)
    body_size = sorted_sizes[0][0]
    
    all_sizes = sorted(size_counter.keys(), reverse=True)
    larger_sizes = [s for s in all_sizes if s > body_size + 1]
    
    size_map = {"body": body_size}
    if len(larger_sizes) >= 1:
        size_map["h1"] = larger_sizes[0]
    if len(larger_sizes) >= 2:
        size_map["h2"] = larger_sizes[1]
    if len(larger_sizes) >= 3:
        size_map["h3"] = larger_sizes[2]
    
    return size_map


def get_heading_level(size: float, size_map: dict, text: str = "", 
                      flags: int = 0, strict: bool = True) -> int:
    """
    ç»¼åˆåˆ¤æ–­æ ‡é¢˜çº§åˆ«
    
    Args:
        size: å­—ä½“å¤§å°
        size_map: å­—ä½“å¤§å°æ˜ å°„
        text: æ–‡æœ¬å†…å®¹ï¼ˆç”¨äºè¾…åŠ©åˆ¤æ–­ï¼‰
        flags: å­—ä½“æ ‡å¿—ï¼ˆbit 4 = ç²—ä½“ï¼‰
        strict: ä¸¥æ ¼æ¨¡å¼ï¼Œéœ€è¦æ»¡è¶³æ›´å¤šæ¡ä»¶
    
    Returns:
        æ ‡é¢˜çº§åˆ«ï¼ˆ0 è¡¨ç¤ºæ­£æ–‡ï¼Œ1-3 è¡¨ç¤º H1-H3ï¼‰
    """
    # åŸºäºå­—ä½“å¤§å°çš„åˆæ­¥åˆ¤æ–­
    level = 0
    if "h1" in size_map and size >= size_map["h1"] - 0.5:
        level = 1
    elif "h2" in size_map and size >= size_map["h2"] - 0.5:
        level = 2
    elif "h3" in size_map and size >= size_map["h3"] - 0.5:
        level = 3
    
    if level == 0:
        return 0
    
    # éä¸¥æ ¼æ¨¡å¼ç›´æ¥è¿”å›ï¼ˆå‘åå…¼å®¹ï¼‰
    if not strict or not text:
        return level
    
    # ä¸¥æ ¼æ¨¡å¼ï¼šé¢å¤–éªŒè¯æ¡ä»¶
    text = text.strip()
    
    # æ’é™¤æ¡ä»¶ï¼šå¤ªé•¿çš„æ–‡æœ¬ä¸å¤ªå¯èƒ½æ˜¯æ ‡é¢˜
    if len(text) > 80:
        return 0
    
    # æ’é™¤æ¡ä»¶ï¼šä»¥å¥å·ç­‰ç»“å°¾çš„å®Œæ•´å¥å­
    sentence_endings = '.ã€‚!ï¼?ï¼Ÿ'
    if text and text[-1] in sentence_endings:
        # ä½†ä¿ç•™ç¼–å·æ ‡é¢˜å¦‚ "1. æ¦‚è¿°" æˆ– "ç¬¬ä¸€ç« ."
        if not re.match(r'^[\dç¬¬]+[.ã€ç« èŠ‚]', text):
            return 0
    
    # åŠ åˆ†æ¡ä»¶ï¼šç²—ä½“æ–‡æœ¬æ›´å¯èƒ½æ˜¯æ ‡é¢˜
    is_bold = flags & 16
    if not is_bold and level >= 2:
        # éç²—ä½“çš„å°æ ‡é¢˜éœ€è¦æ›´ä¸¥æ ¼çš„å­—ä½“å¤§å°å·®å¼‚
        body_size = size_map.get("body", 12)
        if size < body_size + 2:
            return 0
    
    return level

def is_monospace_font(font_name: str) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦ä¸ºç­‰å®½å­—ä½“ï¼ˆé€šå¸¸ç”¨äºä»£ç ï¼‰
    """
    if not font_name:
        return False
    font_lower = font_name.lower()
    mono_fonts = [
        'courier', 'consolas', 'monaco', 'menlo', 'monospace',
        'source code', 'fira code', 'jetbrains', 'inconsolata',
        'dejavu sans mono', 'liberation mono', 'ubuntu mono',
        'roboto mono', 'robotomono', 'sf mono', 'cascadia', 'hack'
    ]
    return any(f in font_lower for f in mono_fonts)


def format_span_text(text: str, flags: int) -> str:
    """æ ¹æ®å­—ä½“æ ‡å¿—æ ¼å¼åŒ–æ–‡æœ¬ï¼ˆç²—ä½“ã€æ–œä½“ï¼‰"""
    text = text.strip()
    if not text:
        return ""
    
    is_bold = flags & 16
    is_italic = flags & 2
    
    if is_bold and is_italic:
        return f"***{text}***"
    elif is_bold:
        return f"**{text}**"
    elif is_italic:
        return f"*{text}*"
    return text


def detect_list_item(text: str) -> tuple:
    """æ£€æµ‹æ˜¯å¦ä¸ºåˆ—è¡¨é¡¹ï¼Œè¿”å› (æ˜¯å¦åˆ—è¡¨, åˆ—è¡¨ç±»å‹, å†…å®¹)"""
    text = text.strip()
    
    ul_patterns = [
        (r'^[â€¢â—â—‹â—¦â–ªâ–¸â–º]\s*', '-'),
        (r'^[-â€“â€”]\s+', '-'),
        (r'^\*\s+', '-'),
    ]
    for pattern, marker in ul_patterns:
        match = re.match(pattern, text)
        if match:
            return (True, 'ul', marker + ' ' + text[match.end():])
    
    ol_pattern = r'^(\d+)[.ã€)]\s*'
    match = re.match(ol_pattern, text)
    if match:
        num = match.group(1)
        return (True, 'ol', f"{num}. " + text[match.end():])
    
    return (False, None, text)


def remove_page_footer(text: str) -> str:
    """
    ç§»é™¤é¡µè„šä¸­çš„é¡µç æ¨¡å¼ï¼Œå¦‚ 'November 2025 8' æˆ– '2025å¹´11æœˆ 8'
    """
    # è‹±æ–‡æœˆä»½ + å¹´ä»½ + é¡µç 
    months_en = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)'
    pattern_en = rf'\s*{months_en}\s+\d{{4}}\s+\d{{1,3}}\s*$'
    text = re.sub(pattern_en, '', text, flags=re.IGNORECASE)
    
    # ä¸­æ–‡æ ¼å¼ï¼š2025å¹´11æœˆ 8
    pattern_cn = r'\s*\d{4}å¹´\d{1,2}æœˆ\s+\d{1,3}\s*$'
    text = re.sub(pattern_cn, '', text)
    
    return text.rstrip()


def detect_headers_footers(doc, threshold_ratio: float = 0.6) -> set:
    """
    ç»Ÿè®¡æ£€æµ‹é¡µçœ‰å’Œé¡µè„š
    
    åŸç†ï¼šé¡µçœ‰å’Œé¡µè„šé€šå¸¸åœ¨æ¯ä¸€é¡µçš„å›ºå®šä½ç½®ï¼ˆé¡¶éƒ¨æˆ–åº•éƒ¨ï¼‰å‡ºç°ç›¸åŒçš„å†…å®¹ã€‚
    æˆ‘ä»¬æ”¶é›†æ‰€æœ‰é¡µé¢çš„é¡¶éƒ¨å’Œåº•éƒ¨æ–‡æœ¬ï¼Œå¦‚æœæŸä¸ªæ–‡æœ¬å‡ºç°çš„é¢‘ç‡è¶…è¿‡é˜ˆå€¼ï¼Œåˆ™è§†ä¸ºå™ªå£°ã€‚
    """
    if len(doc) < 3:
        return set()

    headers = []
    footers = []
    
    # é‡‡æ ·å‰ 20 é¡µå’Œå 20 é¡µï¼ˆé¿å…å¤„ç†å¤ªæ…¢ï¼‰
    pages_to_scan = list(range(len(doc)))
    if len(doc) > 40:
        pages_to_scan = pages_to_scan[:20] + pages_to_scan[-20:]
        
    for i in pages_to_scan:
        page = doc[i]
        rect = page.rect
        h = rect.height
        
        # å®šä¹‰é¡¶éƒ¨å’Œåº•éƒ¨åŒºåŸŸ (å„ 15%)
        top_rect = fitz.Rect(0, 0, rect.width, h * 0.15)
        bottom_rect = fitz.Rect(0, h * 0.85, rect.width, h)
        
        # æå–æ–‡æœ¬å—
        blocks = page.get_text("blocks")
        for b in blocks:
            b_rect = fitz.Rect(b[:4])
            text = b[4].strip()
            if not text:
                continue
            
            # ä½¿ç”¨ç®€å•çš„ç©ºé—´åˆ¤å®š
            if b_rect.intersects(top_rect):
                headers.append(text)
            elif b_rect.intersects(bottom_rect):
                footers.append(text)

    # ç»Ÿè®¡é¢‘ç‡
    noise_texts = set()
    total_scanned = len(pages_to_scan)
    
    for collection in [headers, footers]:
        counter = Counter(collection)
        for text, count in counter.items():
            # if text appears in > 60% of scanned pages, mark as noise
            if count / total_scanned > threshold_ratio:
                noise_texts.add(text)
                
    return noise_texts


def merge_adjacent_headings(elements: list) -> list:
    """
    åˆå¹¶ç›¸é‚»çš„åŒçº§çŸ­æ ‡é¢˜
    ä¾‹å¦‚: '# Agent Tools &' + '# Interoperability' â†’ '# Agent Tools & Interoperability'
    """
    if not elements:
        return elements
    
    merged = []
    i = 0
    
    while i < len(elements):
        el = elements[i]
        
        # åªå¤„ç†æ ‡é¢˜å…ƒç´ 
        if el.get("type") != 0 or not el.get("is_heading"):
            merged.append(el)
            i += 1
            continue
        
        content = el["content"]
        # æå–æ ‡é¢˜çº§åˆ«
        match = re.match(r'^(#{1,6})\s+(.+)$', content)
        if not match:
            merged.append(el)
            i += 1
            continue
        
        level = match.group(1)
        title_text = match.group(2)
        
        # å¦‚æœæ ‡é¢˜è¾ƒçŸ­ä¸”ä¸‹ä¸€ä¸ªä¹Ÿæ˜¯åŒçº§æ ‡é¢˜ï¼Œå°è¯•åˆå¹¶
        j = i + 1
        while j < len(elements) and len(title_text) < 60:
            next_el = elements[j]
            if next_el.get("type") != 0 or not next_el.get("is_heading"):
                break
            
            next_match = re.match(r'^(#{1,6})\s+(.+)$', next_el["content"])
            if not next_match or next_match.group(1) != level:
                break
            
            next_text = next_match.group(2)
            # åªåˆå¹¶çŸ­æ ‡é¢˜ç‰‡æ®µ
            if len(next_text) > 40:
                break
            
            # åˆå¹¶
            title_text += " " + next_text
            j += 1
        
        # åˆ›å»ºåˆå¹¶åçš„å…ƒç´ 
        merged_el = el.copy()
        merged_el["content"] = f"{level} {title_text}"
        merged.append(merged_el)
        i = j
    
    return merged


def clean_text(text: str) -> str:
    """æ¸…ç†æå–çš„æ–‡æœ¬"""
    lines = text.split('\n')
    cleaned_lines = []
    prev_empty = False
    
    for line in lines:
        line = line.rstrip()
        is_empty = len(line.strip()) == 0
        
        if is_empty:
            if not prev_empty:
                cleaned_lines.append('')
            prev_empty = True
        else:
            cleaned_lines.append(line)
            prev_empty = False
    
    return '\n'.join(cleaned_lines)


def merge_adjacent_formatting(text: str) -> str:
    """åˆå¹¶ç›¸é‚»çš„æ ¼å¼æ ‡è®°ï¼Œå¦‚ **text1****text2** â†’ **text1 text2**"""
    text = re.sub(r'\*\*\s*\*\*', ' ', text)
    text = re.sub(r'\*\s*\*', ' ', text)
    text = re.sub(r'\*\*\*\s*\*\*\*', ' ', text)
    return text


def is_sentence_end(text: str) -> bool:
    """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä»¥å¥æœ«æ ‡ç‚¹ç»“å°¾"""
    text = text.rstrip()
    if not text:
        return True
    end_puncts = '.ã€‚!ï¼?ï¼Ÿ:ï¼š;ï¼›'
    return text[-1] in end_puncts


def should_merge_lines(current: dict, next_line: dict) -> bool:
    """åˆ¤æ–­ä¸¤è¡Œæ˜¯å¦åº”è¯¥åˆå¹¶ä¸ºåŒä¸€æ®µè½"""
    if current.get("is_heading") or next_line.get("is_heading"):
        return False
    if current.get("is_list") or next_line.get("is_list"):
        return False
    if is_sentence_end(current.get("content", "")):
        return False
    return True


def extract_pdf_to_markdown(pdf_path: str, output_path: str = None) -> str:
    """
    ä» PDF æå–æ–‡æœ¬ã€å›¾ç‰‡å’Œè¡¨æ ¼å¹¶è½¬æ¢ä¸º Markdown
    """
    try:
        doc = fitz.open(pdf_path)
    except Exception as e:
        print(f"âŒ æ— æ³•æ‰“å¼€ PDF æ–‡ä»¶: {e}")
        return ""
    
    filename = Path(pdf_path).stem
    title = re.sub(r'^\d+-', '', filename).strip()
    
    print(f"ğŸ“„ åˆ†ææ–‡æ¡£ç»“æ„...")
    size_map = analyze_font_sizes(doc)
    print(f"   å­—ä½“å¤§å°æ˜ å°„: æ­£æ–‡={size_map.get('body', 'N/A')}, " +
          f"H1={size_map.get('h1', 'N/A')}, H2={size_map.get('h2', 'N/A')}, H3={size_map.get('h3', 'N/A')}")
    
    print(f"ğŸ§¹ æ£€æµ‹é‡å¤é¡µçœ‰/é¡µè„š...")
    noise_texts = detect_headers_footers(doc)
    if noise_texts:
        print(f"   å‘ç° {len(noise_texts)} ä¸ªé‡å¤å™ªå£°æ–‡æœ¬ (å°†è¢«ç§»é™¤):")
        for t in list(noise_texts)[:3]:
            print(f"     - {t[:30]}...")
            
    markdown_content = f"# {title}\n\n"
    
    img_dir = None
    rel_img_dir = "images"
    if output_path:
        output_path = Path(output_path)
        img_dir = output_path.parent / rel_img_dir
        if not img_dir.exists():
            img_dir.mkdir(parents=True, exist_ok=True)
            
    img_count = 0
    
    for page_num, page in enumerate(doc, 1):
        if page_num > 1:
            # æ·»åŠ åˆ†é¡µç¬¦ï¼Œæ–¹ä¾¿ LLM ç†è§£ä¸Šä¸‹æ–‡åˆ‡åˆ†
            markdown_content += f"\n\n<!-- Page {page_num} -->\n\n"
            
        try:
            tabs = page.find_tables()
        except Exception:
            tabs = []
            
        tab_rects = [fitz.Rect(t.bbox) for t in tabs]
        
        page_elements = []
        
        for tab in tabs:
            page_elements.append({
                "y0": tab.bbox[1],
                "type": 2,
                "content": tab.to_markdown()
            })
            print(f"  âœ“ å‘ç°è¡¨æ ¼: P{page_num}")

        blocks = page.get_text("dict")["blocks"]
        
        for block in blocks:
            block_rect = fitz.Rect(block["bbox"])
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºè¡¨æ ¼å†…å®¹
            is_in_table = False
            for tab_rect in tab_rects:
                intersect = block_rect & tab_rect
                if intersect.get_area() > 0.6 * block_rect.get_area():
                    is_in_table = True
                    break
            
            if is_in_table:
                continue
                
            if block["type"] == 0:
                # æ£€æŸ¥æ˜¯å¦ä¸ºéœ€è¦è¿‡æ»¤çš„å™ªå£°æ–‡æœ¬ (Whole block match)
                block_text_full = "".join([span["text"] for line in block["lines"] for span in line["spans"]]).strip()
                if block_text_full in noise_texts:
                    continue
                
                for line in block["lines"]:
                    line_text = ""
                    line_size = 0
                    line_flags = 0
                    span_count = 0
                    is_code_line = False
                    
                    formatted_spans = []
                    for span in line["spans"]:
                        span_text = span["text"]
                        if not span_text.strip():
                            if span_text:
                                formatted_spans.append(span_text)
                            continue
                        
                        span_size = span["size"]
                        span_flags = span["flags"]
                        
                        line_size = max(line_size, span_size)
                        line_flags |= span_flags
                        span_count += 1
                        
                        heading_level = get_heading_level(span_size, size_map, span_text, span_flags)
                        
                        # æ£€æµ‹ä»£ç å­—ä½“
                        font_name = span.get("font", "")
                        if is_monospace_font(font_name):
                            is_code_line = True
                            formatted_spans.append(span_text)  # ä»£ç ä¸åŠ æ ¼å¼
                        elif heading_level > 0:
                            formatted_spans.append(span_text.strip())
                        else:
                            formatted_spans.append(format_span_text(span_text, span_flags))
                    
                    line_text = ''.join(formatted_spans).strip()
                    if not line_text:
                        continue
                    
                    # äºŒæ¬¡æ£€æŸ¥ï¼šè¡Œçº§åˆ«æ˜¯å¦åŒ¹é…å™ªå£° (æœ‰æ—¶ block è¢«åˆ‡åˆ†äº†)
                    if line_text in noise_texts:
                        continue

                    line_text = merge_adjacent_formatting(line_text)
                    
                    heading_level = get_heading_level(line_size, size_map, line_text, line_flags)
                    
                    is_list, list_type, list_content = detect_list_item(line_text)
                    
                    if heading_level > 0:
                        prefix = '#' * heading_level + ' '
                        clean_line = re.sub(r'\*+([^*]+)\*+', r'\1', line_text)
                        final_text = prefix + clean_line
                    elif is_list:
                        final_text = list_content
                    else:
                        final_text = line_text
                    
                    page_elements.append({
                        "y0": line["bbox"][1],
                        "type": 0,
                        "content": final_text,
                        "is_heading": heading_level > 0,
                        "is_list": is_list,
                        "is_code": is_code_line
                    })
                    
            elif block["type"] == 1:
                page_elements.append({
                    "y0": block["bbox"][1],
                    "type": 1,
                    "content": block
                })
        
        page_elements.sort(key=lambda x: x["y0"])
        
        # åˆå¹¶ç›¸é‚»çš„åŒçº§çŸ­æ ‡é¢˜
        page_elements = merge_adjacent_headings(page_elements)
        
        merged_elements = []
        i = 0
        while i < len(page_elements):
            el = page_elements[i]
            if el["type"] == 0 and not el.get("is_heading") and not el.get("is_list"):
                merged_content = el["content"]
                j = i + 1
                while j < len(page_elements):
                    next_el = page_elements[j]
                    if next_el["type"] != 0:
                        break
                    if not should_merge_lines({"content": merged_content, "is_heading": False, "is_list": False}, next_el):
                        break
                    merged_content += " " + next_el["content"]
                    j += 1
                merged_elements.append({
                    "type": 0,
                    "content": remove_page_footer(merged_content),
                    "is_heading": False,
                    "is_list": False
                })
                i = j
            else:
                merged_elements.append(el)
                i += 1
        
        prev_was_list = False
        prev_was_code = False
        code_block_lines = []
        
        def flush_code_block():
            """è¾“å‡ºç´¯ç§¯çš„ä»£ç å—"""
            nonlocal code_block_lines, markdown_content
            if code_block_lines:
                markdown_content += "```\n"
                markdown_content += "\n".join(code_block_lines) + "\n"
                markdown_content += "```\n\n"
                code_block_lines = []
        
        for el in merged_elements:
            if el["type"] == 0:
                is_list = el.get("is_list", False)
                is_heading = el.get("is_heading", False)
                is_code = el.get("is_code", False)
                
                if is_code:
                    # ç´¯ç§¯ä»£ç è¡Œ
                    if prev_was_list:
                        markdown_content += "\n"
                        prev_was_list = False
                    code_block_lines.append(el["content"])
                    prev_was_code = True
                else:
                    # éä»£ç è¡Œï¼Œå…ˆè¾“å‡ºç´¯ç§¯çš„ä»£ç å—
                    if prev_was_code:
                        flush_code_block()
                        prev_was_code = False
                    
                    if is_heading:
                        if prev_was_list:
                            markdown_content += "\n"
                        markdown_content += el["content"] + "\n\n"
                        prev_was_list = False
                    elif is_list:
                        markdown_content += el["content"] + "\n"
                        prev_was_list = True
                    else:
                        if prev_was_list:
                            markdown_content += "\n"
                        markdown_content += el["content"] + "\n\n"
                        prev_was_list = False
                    
            elif el["type"] == 2:
                if prev_was_code:
                    flush_code_block()
                    prev_was_code = False
                if prev_was_list:
                    markdown_content += "\n"
                markdown_content += el["content"] + "\n\n"
                prev_was_list = False
                
            elif el["type"] == 1:
                if prev_was_code:
                    flush_code_block()
                    prev_was_code = False
                if img_dir:
                    block = el["content"]
                    ext = block["ext"]
                    image_data = block["image"]
                    safe_filename = filename.replace(" ", "_")
                    image_name = f"{safe_filename}_p{page_num}_{img_count}.{ext}"
                    image_path = img_dir / image_name
                    
                    try:
                        with open(image_path, "wb") as f:
                            f.write(image_data)
                        
                        if prev_was_list:
                            markdown_content += "\n"
                        markdown_content += f"![{image_name}]({rel_img_dir}/{image_name})\n\n"
                        img_count += 1
                        prev_was_list = False
                        print(f"  âœ“ æå–å›¾ç‰‡: {image_name}")
                    except Exception as e:
                        print(f"  âš ï¸ å›¾ç‰‡ä¿å­˜å¤±è´¥: {e}")
        
        # é¡µé¢æœ«å°¾åˆ·æ–°ä»£ç å—
        if prev_was_code:
            flush_code_block()
    
    doc.close()
    
    markdown_content = re.sub(r'\n{3,}', '\n\n', markdown_content)
    markdown_content = markdown_content.strip() + "\n"
    
    if output_path:
        os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        print(f"âœ“ ä¿å­˜ Markdown åˆ°: {output_path}")
    
    return markdown_content


def process_directory(input_dir: str, output_dir: str = None):
    """å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰ PDF æ–‡ä»¶"""
    input_path = Path(input_dir)
    
    if output_dir:
        output_path = Path(output_dir)
    else:
        output_path = input_path
    
    pdf_files = sorted(input_path.glob('*.pdf'))
    
    print(f"æ‰¾åˆ° {len(pdf_files)} ä¸ª PDF æ–‡ä»¶")
    
    for pdf_file in pdf_files:
        output_file = output_path / (pdf_file.stem + '.md')
        print(f"å¤„ç†: {pdf_file.name}")
        extract_pdf_to_markdown(str(pdf_file), str(output_file))


def main():
    parser = argparse.ArgumentParser(
        description='PDF è½¬ Markdown å·¥å…·ï¼ˆæ”¯æŒç»“æ„è¯†åˆ«ä¸ LLM ä¼˜åŒ–ï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ç¤ºä¾‹:
  python pdf_to_md.py book.pdf                    # è½¬æ¢å•ä¸ªæ–‡ä»¶
  python pdf_to_md.py book.pdf -o output.md      # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  python pdf_to_md.py ./pdfs                      # è½¬æ¢ç›®å½•ä¸‹æ‰€æœ‰ PDF
  python pdf_to_md.py ./pdfs -o ./markdown       # æŒ‡å®šè¾“å‡ºç›®å½•

ç»“æ„è¯†åˆ«åŠŸèƒ½:
  - è‡ªåŠ¨è¯†åˆ«æ ‡é¢˜å±‚çº§ï¼ˆåŸºäºå­—ä½“å¤§å°ï¼‰
  - è¯†åˆ«ç²—ä½“å’Œæ–œä½“æ–‡æœ¬
  - è¯†åˆ«æœ‰åºå’Œæ— åºåˆ—è¡¨
  - æå–è¡¨æ ¼å¹¶è½¬ä¸º Markdown æ ¼å¼ (è‡ªåŠ¨å»é‡)
  - [æ–°] æ™ºèƒ½æ£€æµ‹å¹¶ç§»é™¤é¡µé¢é‡å¤çš„é¡µçœ‰/é¡µè„š
  - [æ–°] æ·»åŠ  <!-- Page N --> åˆ†é¡µç¬¦ï¼Œè¾…åŠ© LLM ç†è§£
'''
    )
    
    parser.add_argument('input', help='PDF æ–‡ä»¶æˆ–åŒ…å« PDF çš„ç›®å½•')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶æˆ–ç›®å½•')
    
    args = parser.parse_args()
    
    input_path = Path(args.input)
    
    if input_path.is_file():
        output = args.output or str(input_path.with_suffix('.md'))
        extract_pdf_to_markdown(str(input_path), output)
    elif input_path.is_dir():
        process_directory(str(input_path), args.output)
    else:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶æˆ–ç›®å½•: {args.input}")
        return 1
    
    return 0


if __name__ == '__main__':
    exit(main())
